---
layout: post
title: "Everything is the Big Bang's Fault!"
date: 2018-11-18
excerpt: "Can AI actually be sentient?"
tags: [Ted Chiang,AI,Determinism]
comments: true
---


Ted Chiang’s “The Lifecycle of Software Objects” was an interesting read for many reasons, but mainly, for me, it was because it forced the characters and the reader alike to ask what qualifies as sentience and whether or not artificial intelligence can have it. 

Throughout the last part of the novella, the digients are at risk of getting suspended and it seems the only way to save them is to sell them to Binary Desire, a company that sells sex dolls. The owners are unwilling to sell copies of their digients because they do not trust that they will not be mistreated and because they believe whatever bond they will have with the user will be inorganic and fabricated. The matter gets complicated for Derek because his digients tell him they want to take this job. He has problems with Ana over this matter because she doesn’t believe the digients can give consent to what would happen to them since they would be manipulated by the reprogramming in their reward system and by the users themselves. Derek ultimately gives his digients corporate status and lets them choose to sell themselves to Binary Desire.

Sentience in AI and how it is affected by human interference in code and interaction raises the philosophical question of determinism in both humans and AI. Determinism is the doctrine that all events are ultimately determined by external causes. How much of our thoughts and actions are predetermined? If everything is a result of some outside force that we have no control over, are any of our thoughts our own? Is there such a thing as free will?

All of the actions that AI takes is a result of a command written in their code and they are just performing functions. Their sentience is nullified by the intent that humans had when creating them. Similar to how AI is programmed by humans, humans are preprogrammed with commands and functions in their DNA by nature. Humans are only performing functions that will help them survive. For both, all of their actions are not actions, but reactions to external threats and benefits.

External interference also plays into how both AI and humans are developed. The digients in the novella were raised similarly to how humans are raised from infancy. They are trained and taught to speak and bond with their caretaker. The digients bond with the user and a child bonds with its parent. Later in the book, the digents’ owners are unsettled by the artificial nature of how the copies of the digients would bond with their owners through Binary Desire. The process for how the original digients bonded is basically similar to how the copies would bond. They would care for whoever rewarded them because the function of caring warrants a reward. This is similar to how humans would build relationships and personalities - they bond with the people that care for them.

Under determinism, even the actions that seem more deliberate are an inevitable result of nature and coding. Determinism is the basis used to argue that AI is not actually sentient. To me this seems an unfair judgement, because people do not normally apply the same logic to themselves. If AI is not sentient and does not have free will because of its programming, then, because of nature, humans are the same.
